## Chapter 1 - Deploying Infrastructure with Terraform

In this chapter, we will be standing up basic infrastructure with Terraform to support our full stack app buildout.  A more robust tutorial can be found in the [accompanying blog post for this chapter]().


### Prerequisites
- [Google Cloud SDK](https://cloud.google.com/sdk) installed on your machine
- [kubectl](https://kubernetes.io/docs/tasks/tools/install-kubectl/) installed on your machine
- [Terraform](https://learn.hashicorp.com/terraform/getting-started/install.html) (0.12.x) installed on your machine
- [Direnv]
- An active [Google Cloud Platform Billing Account](https://cloud.google.com/billing/docs/how-to/manage-billing-account)

### Setting up the Project

Login to GCloud, making sure to use an account that has access to the billing account mentioned in the prerequisites, e.g. the account that created the billing account.
```bash
gcloud auth login
```

Set the compute zone
```bash
gcloud config set compute/zone us-central1-a
```

Create an `.envrc.private` that `.envrc` can source using `.envrc.private.example` as a template.  Enter values that you want for the deployed
postgres instance username and password
```bash
export TF_VAR_cloud_sql_username=<DESIRED USERNAME>
export TF_VAR_cloud_sql_password=<DESIRED STRONG PASSWORD>
```

Copy the `.envrc` from this project to your own `.envrc`.  Set the `PROJECT_ID` environment variable in `.envrc`
```bash
...

export PROJECT_ID=<YOUR_GLOBALLY_UNIQUE_PROJECT_NAME>

...
```

Tell `direnv` to load the changes in the `.envrc` file
```bash
direnv allow
```

Create a project
```bash
gcloud projects create $PROJECT_ID
```

Get existing organizational billing accounts
```bash
gcloud beta billing accounts list
```

Link an existing billing account to the project
```bash
gcloud beta billing projects link $PROJECT_ID --billing-account=<YOUR BILLING ACCOUNT ID>
```

Set the active project
```bash
gcloud config set project $PROJECT_ID
```

### Configuring Terraform Boilerplate

Enabled the Cloud Resource Manager API for the project
```bash
gcloud services enable cloudresourcemanager.googleapis.com 
```

Create the terraform service account
```bash
gcloud beta iam service-accounts create sa-terraform \
    --description "Terraform service account" \
    --display-name "Terraform SA"
```

Grant the service account ownership roles (for the sake of brevity)
```bash
gcloud projects add-iam-policy-binding $PROJECT_ID \
    --member serviceAccount:sa-terraform@$PROJECT_ID.iam.gserviceaccount.com \
    --role roles/owner
```

Create a local key for the service account that the terraform CLI can use
```bash
gcloud iam service-accounts keys create ~/.terraform/service-account.json \
    --iam-account sa-terraform@$PROJECT_ID.iam.gserviceaccount.com
```

Create a storage bucket to store terraform state
```bash
gsutil mb -p $PROJECT_ID gs://$PROJECT_ID-tf-state
```

### Deploying Infrastructure

**Note on this section**

With Terraform 0.12, I've noticed a random coming back from Terraform 0.12: 

```bash
Error: Provider produced inconsistent final plan
```

If you run into any of these, you should be able to simply re-run the `terraform apply` command until it stops.  Terraform operations are [idempotent](https://www.restapitutorial.com/lessons/idempotency.html), so you don't have to worry about the tool performing duplicate work.  It will simply do what is necessary to finish bringing about the state stored in your terraform files that isn't yet applied to your infrastructure.

**/endnote**

First, create a folder for the Terraform code
```bash
mkdir -p ops/terraform
```

Setup a main terraform file in `ops/terraform/main.tf` from the file in this project, updating the `terraform.backend.bucket` like so: 
```tf

terraform {
  ...
  backend "gcs" {
    bucket      = "<YOUR $PROJECT_ID ENV VAR VALUE>-tf-state"
    ...
  }
}

```

Init the project
```bash
terraform init ops/terraform
```

#### Deploying GKE

Add GKE in `ops/terraform/gke` from the file in this project

Apply the changes to create the GKE cluster
```bash
terraform apply ops/terraform
```

Configure `kubectl` credentials to use GKE
```bash
gcloud container clusters get-credentials main-cluster
```

#### Deploying Postgres via Google Cloud SQL

Add SQL (Postgres) in `ops/terraform/sql` from the file in this project

Apply the changes to create the Postgres instance
```bash
terraform apply ops/terraform
```

Get the `PRIVATE_ADDRESS` ip address of the Cloud SQL instance
```bash
gcloud beta sql instances list
```

Let's test connectivity between GKE and Cloud SQL by running a temporary [postgres image](https://hub.docker.com/_/postgres) and invoking the [psql](https://www.postgresql.org/docs/9.3/app-psql.html) command to ping the Cloud SQL Postgres instance

Spawn the container and connect to a bash shell
```bash
kubectl run tmp-postgres --rm -it --image postgres /bin/bash
```

Run `psql` inside of the bash shell to test connectivity
```bash
psql \
  -h <PRIVATE_ADDRESS MENTIONED ABOVE> \
  -U <VALUE OF OF TF_VAR_cloud_sql_username from .envrc.secret>
  -d production # or whatever you named the database in terraform

# Password will be value of of TF_VAR_cloud_sql_password
# in .envrc.private
```

It should connect.  Enter `exit` to quit `psql` and then `exit` again to exit the bash session and Kubernetes will automatically destroy the temporary container due to the `--rm` flag we gave `kubectl`

#### Deploying Redis via Google Cloud Memorystore

Add Memorystore (Redis) in `ops/terraform/memorystore.tf` from the file in this project

Apply the changes to create the Redis instance
```bash
terraform apply ops/terraform
```

Get the `HOST` ip address of the Redis instance, substituting a different region code if you didn't use `us-central1-a` as the location id in the terraform file

```
gcloud beta redis instances list --region us-central1
```

Let's test connectivity between GKE and Redis by running a temporary [redis image](https://hub.docker.com/_/redis) and invoking the [redis-cli](https://redis.io/topics/rediscli) command to ping the Memorystore Redis instance

Spawn the container and connect to a bash shell
```bash
kubectl run tmp-redis --rm -it --image redis /bin/bash
```

Run `redis-cli` inside of the bash shell to test connectivity
```bash
redis-cli -h <HOST MENTIONED ABOVE> ping
```

You should see `PONG` from stdout.  Exit the session with `exit` and Kubernetes will automatically destroy the temporary container

Boom, you now have a fully running deployment on GCP!  Next up is [Chapter 2](./2.md)

*Wish your engineering team knew how to do this kind of thing?  BoltSource is available to help your team and company push the envelope and deliver software products that are better, faster, and stronger with our team of Silicon Valley Veterans and Open Source Savants.  [Book a free exploration call today](https://calendly.com/boltsource-andrew/exploration)*